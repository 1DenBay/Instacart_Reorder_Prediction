{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAGGLE ile hibrit model ÅŸeklinde gidilmektedir. Veri iÅŸlemesi, hazÄ±rlÄ±ÄŸÄ± lokalde yapÄ±lÄ±rken; Model eÄŸitimi kaggle Ã¼zerinden yapÄ±lmaktadÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu dosya kaggle da eÄŸitilen modelin kodlarÄ±nÄ± ve geliÅŸimini arÅŸivlemek aÃ§Ä±sÄ±ndan birebir kod ve aÃ§Ä±klamalarÄ±dÄ±r. (Ã‡Ä±ktÄ±larÄ± Kendiniz Ã‡alÄ±ÅŸtÄ±rarak GÃ¶rebilir yada Kaggle HesabÄ±ma Gidebilirsiniz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" VERÄ° YÃœKLEME \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model iÃ§in hazÄ±rladÄ±ÄŸÄ±mÄ±z train.data verisi seti\n",
    "df = pd.read_csv(\"/kaggle/input/instacart-features-local/train_data.csv\")\n",
    "\n",
    "print(f\"âœ… Veri yÃ¼klendi! Boyut: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create_Dataset dosyasÄ± ile son hale getirdiÄŸimiz eÄŸitim iÃ§in veri setini sisteme yÃ¼kledik ve burada Ã§ekiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEÄÄ°ÅKENLERÄ°N HAZIRLANMASI \"\"\"\n",
    "\n",
    "X = df.drop(['user_id', 'product_id', 'reordered'], axis=1) # deÄŸiÅŸkenler\n",
    "y = df['reordered'] # hedef\n",
    "\n",
    "# %80 EÄŸitim, %20 test\n",
    "print(\"ğŸ”ª Veri setleri ayrÄ±lÄ±yor...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"EÄŸitim Seti: {X_train.shape}\")\n",
    "print(f\"Test Seti:   {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin kullanÄ±cÄ±, Ã¼rÃ¼n ve tahmin etmesi gereken (hedef deÄŸiÅŸken) sÃ¼tunlarÄ±nÄ± gÃ¶rmemesi iÃ§in kaldÄ±rÄ±yoruz diÄŸerlerini alacak. eÄŸer kaldÄ±rmaz isek model bunlarÄ± baz alarak Ã¶ÄŸrenmek yerine ezber yapar. Yani ahmet ÅŸunu almÄ±ÅŸ, muz bu kadar alÄ±nÄ±yor gibi ezberden kaÃ§Ä±nsÄ±n. EÄŸer Ã¼rÃ¼n popÃ¼lerse ve kullanÄ±cÄ± daha Ã¶nce Ã§ok aldÄ±ysa cevap Evet' yani tekrar alÄ±r demesi lazÄ±m bu mantÄ±kla yaklaÅŸmalÄ±.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" XGBOOST MODELÄ°NÄ°N AYARLARI \"\"\"\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', #Â Ä°kili sÄ±nÄ±flandÄ±rmadÄ±r. (binary ikili durumu ifade eder evet-hayÄ±r,alacak-almÄ±ycak gibi, logistic ise sÄ±nÄ±flandÄ±rma iÃ§in kullanÄ±rÄ±z direkt 0,1 vermesin kÃ¼sÃ¼ratlÄ±da versin)\n",
    "    eval_metric='logloss', # puan sistemi (Ã‡ok eminse ve yanlÄ±ÅŸ Ã§Ä±karsa bÃ¼yÃ¼k ceza gibi tahminle orantÄ±lÄ± ceza)\n",
    "    n_estimators=1000,      # AÄŸaÃ§ sayÄ±sÄ±\n",
    "    learning_rate=0.05,     # Ã–ÄŸrenme hÄ±zÄ±\n",
    "    max_depth=6,            # AÄŸaÃ§ derinliÄŸi\n",
    "    tree_method='hist',     # HÄ±zlandÄ±rma iÃ§in (histogram ile veriyi gruplayarak iÅŸlem yapsÄ±n. hÄ±z katar.)\n",
    "    device='cuda',          # GPU kullanÄ±mÄ± (EÄŸer GPU aÃ§tÄ±ysan 'cuda', aÃ§madÄ±ysan 'cpu' yap)\n",
    "    early_stopping_rounds=50 # EÄŸer 50 tur boyunca iyileÅŸme olmazsa dur\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)], # her aÄŸaÃ§tan sonra gÃ¶rmediÄŸi verilerle test yapra\n",
    "    verbose=100  # Her 100 adÄ±mda(aÄŸaÃ§ta) bir durum raporu ver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TAHMÄ°N \"\"\"\n",
    "\n",
    "# Tahmin yap\n",
    "y_pred = model.predict(X_val) #Â x_val verileri ile tahmin ettirme\n",
    "# 0 ve 1 leden oluÅŸan tahmin sonuÃ§larÄ± y_pred de\n",
    "\n",
    "# Raporla\n",
    "print(\"ğŸ“Š Model PerformansÄ±:\")\n",
    "print(classification_report(y_val, y_pred)) # y_val gerÃ§ek cevaplar ile y_pred tahminlerin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±\n",
    "\n",
    "# Hangi Ã¶zellik en Ã¶nemlisi (Interpretabilitiy)\n",
    "xgb.plot_importance(model, max_num_features=10)  # karar verirken en Ã§ok kullandÄ±ÄŸÄ± Ã¶zellikleri sÄ±ralar\n",
    "plt.title(\"Hangi Ã–zellik Daha Ã–nemli?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() metodunda varsayÄ±lan olarak eÅŸik deÄŸer %50 dir. Yani 1 (alÄ±r) sonucunu vermesi iÃ§in %50.01 ikna olmasÄ± yeterlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_report() metodu ceaplarÄ±n kontrolÃ¼nÃ¼ yapar. Direkt ÅŸu kadar bildi (accuracy) Ã¶lÃ§mez genel bir test yapar. \n",
    "\n",
    "Testte Precision (Kesinlik): \"Alacak\" dediklerinin yÃ¼zde kaÃ§Ä± gerÃ§ekten aldÄ±\n",
    "\n",
    "Recall (DuyarlÄ±lÄ±k - En Ã–nemlisi): GerÃ§ekten alanlarÄ±n yÃ¼zde kaÃ§Ä±nÄ± yakalayabildi\n",
    "\n",
    "F1-Score: Precision ve Recall'un ortalamasÄ±. Modelin genel dengesi. (direkt bu metrik Ã§ok ÅŸey ifade eder)\n",
    "\n",
    "Support: o sÄ±nÄ±ftan (0 veya 1) test setinde kaÃ§ tane Ã¶rnek olduÄŸu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretability kÄ±smÄ± analiz iÃ§in Ã§ok Ã¶nemlidir. Ä°lk sonuÃ§lar genelde hiÃ§ iÃ§ aÃ§Ä±cÄ± olmayakcaktÄ±r. Bunun tedavisinide en kÄ±sa ve kesin yoldan bu adÄ±m ile saptayabilir. Modele bu kararlarÄ± verirken hangi Ã¶zellikleri kullandÄ±n diye sorar. Bu da model gerÃ§ekten bizim istediÄŸimiz mantÄ±k da dÃ¼ÅŸÃ¼nÃ¼p dÃ¼ÅŸÃ¼nmediÄŸini gÃ¶sterir ve nokta atÄ±ÅŸÄ± tedavi yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" KarmaÅŸÄ±klÄ±k Matrisi incelemesi ve En iyi EÅŸik DeÄŸerini Bulma \"\"\"\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 1-Tahminlerin ihtimal oranlarÄ± (yani karar verirken ne kadar oranlar ile verdin)\n",
    "print(\"OlasÄ±lÄ±klar hesaplanÄ±yor\")\n",
    "y_pred_probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "\n",
    "# 2-En iyi eÅŸik deÄŸerini (Threshold) bulma dÃ¶ngÃ¼sÃ¼\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "results = []\n",
    "\n",
    "print(\"En iyi eÅŸik deÄŸeri aranÄ±yor\")\n",
    "\n",
    "# 0.10'dan 0.50'ye kadar 0.02 adÄ±m adÄ±m dene\n",
    "for threshold in np.arange(0.1, 0.51, 0.02):\n",
    "    # OlasÄ±lÄ±k > threshold ise 1 yap, deÄŸilse 0\n",
    "    preds_custom = (y_pred_probs > threshold).astype(int) # karÅŸÄ±laÅŸtÄ±rma\n",
    "    \n",
    "    # F1 Skorunu hesapla (Class 1 iÃ§in)\n",
    "    f1 = f1_score(y_val, preds_custom) # her eÅŸiÄŸe gÃ¶re hesaplamadÄ±ÄŸÄ±mÄ±z sÄ±nÄ±f ile gerÃ§ek deÄŸerler f1 skorunu hesapla\n",
    "    results.append((threshold, f1)) #Â bu Ã¶lÃ§Ã¼mleri karÅŸÄ±laÅŸtÄ±rmak Ã¼zere listeye atÄ±yoruz\n",
    "    \n",
    "    print(f\"   EÅŸik: {threshold:.2f} -> F1 Score: {f1:.4f}\") #Â her dÃ¶ngÃ¼ sonucu\n",
    "    \n",
    "    # en iyi f1 skoru seÃ§imi\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"EN Ä°YÄ° EÅÄ°K DEÄERÄ°: {best_threshold:.2f}\")\n",
    "print(f\"Yeni F1 Skoru: {best_f1:.4f}\")\n",
    "\n",
    "\n",
    "# 3-En iyi eÅŸik ile DETAYLI raporu bas\n",
    "final_preds = (y_pred_probs > best_threshold).astype(int) #Â en iyi eÅŸik deÄŸeri al\n",
    "\n",
    "print(\"\\nOptimize EdilmiÅŸ Rapor:\")\n",
    "print(classification_report(y_val, final_preds)) #Â alÄ±nan deÄŸerler tekrardan report metodu ile raporla\n",
    "\n",
    "\n",
    "# 4-KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix) - Neyi ne kadar doÄŸru bildik gÃ¶rmek iÃ§in\n",
    "cm = confusion_matrix(y_val, final_preds) #Â cevaplar ile bizim en iyi f1 li tahmnilerimiz\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix (Threshold: {best_threshold:.2f})')\n",
    "plt.ylabel('GerÃ§ek DeÄŸer')\n",
    "plt.xlabel('Tahmin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba() ile bu sefer ihtimalleri alÄ±yoruz. yani sen sÄ±nÄ±flandÄ±rma (0 alma, 1 al) yaparken %50 Ã¼stÃ¼ olunca 1 diyosun ama  ne kadar oran verdin her veri iÃ§in diye soruyoruz. geriye her tahmini iÃ§in [[0.3, 0.7], [0.8, 0.2], ...] gibi bir Ã§Ä±ktÄ± dÃ¶ner biz de sadece saÄŸdaki yani 1.indeksteki 1(alÄ±r) iÃ§in olan oranlarÄ± alÄ±yoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred default olarak threshold deÄŸerini %50 alÄ±r yani 50.1 olduÄŸu an 1 verir. Burada Ã§ok korkak davrandÄ±ÄŸÄ± tespit ettik Ã§Ä±kan sonuÃ§larda. Bu deÄŸerin en optimum sonuÃ§larÄ± ne kadarken verdiÄŸini gÃ¶rmek iÃ§in tÃ¼m deÄŸeleri ufak adÄ±mlarla deÄŸiÅŸtire deÄŸiÅŸtire deniyoruz. ihtimalleri aldÄ±ÄŸÄ±mÄ±z kÄ±sÄ±m ile sÃ¼rekli denediÄŸimiz eÅŸik deÄŸeri karÅŸÄ±laÅŸtÄ±rÄ±p deniyoruz. En iyi sonucu veren f1 skorlu deÄŸerli report fonkisyonu ile detaylÄ± raporluyoruz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son olarak karÄ±ÅŸÄ±klÄ±k matrisi ile rÃ¶ntgen Ã§ekiyoruz. Bu matriste satÄ±rlar GerÃ§ek Durumu, sÃ¼tunlar ise Modelin Tahminini gÃ¶sterir. Her kutunun ise ayrÄ± bir anlamÄ± vardÄ±r. \n",
    "\n",
    "Sol Ã¼st kutu (TN-TRUE NEGATÄ°VE) Buraya sessiz doÄŸru deneriz. burada mÃ¼ÅŸterinin almayacaÄŸÄ± Ã¼rÃ¼ne modelinde almayacak demesidir. saten bu durum her problemde genelde doÄŸrudur. Ã‡Ã¼nkÃ¼ bu durumda bulunan bi ton veri saten hep vardÄ±r.\n",
    "\n",
    "SaÄŸ Ã¼st kutu (FP-FALSE POSITIVE) YanlÄ±ÅŸ alarm verdiÄŸimiz durumlar. MÃ¼ÅŸterinin almayacaÄŸÄ± Ã¼rÃ¼ne modelin alacak demesidir. Bu oran son yaptÄ±ÄŸÄ±mÄ±z eÅŸik deÄŸeri 50 den 20 ye dÃ¼ÅŸÃ¼rme iÅŸlemimizden sonra ciddi arttÄ±. Ã‡Ã¼nkÃ¼ model Ã§ok daha sÄ±k alacak dediÄŸi iÃ§in hata oranÄ±da arttÄ±. Bu sorun bu problem iÃ§in gÃ¶z ardÄ± edilebilir Ã§Ã¼nkÃ¼ mÃ¼ÅŸteriye Ã¼rÃ¼n Ã¶nerme maliyeti dÃ¼ÅŸÃ¼ktÃ¼r ama bu Ã¶nermeye karÅŸÄ±lÄ±k vermesi Ã¶nemli olduÄŸundan maliyet-kazanÃ§ oranÄ±mÄ±z yÃ¼ksektir bundan dolayÄ± burada ki hata payÄ± gÃ¶z ardÄ± edilebilir. (biz az ihtimalde olsa Ã¶nerelim maliyeti yok ya alÄ±rsa gibi)\n",
    "\n",
    "Sol alt kutu (FN-FALSE NEGATIVE) Bu kÄ±sÄ±m farkÄ± yaratacaÄŸÄ±mÄ±z, problemin ana amaÃ§ kÄ±smÄ±dÄ±r. MÃ¼ÅŸterinin aldÄ±ÄŸÄ± ancak biz almayacak diyip de Ã¶nermede bulunmadÄ±ÄŸÄ±mÄ±z kÄ±sÄ±mdÄ±r. EÅŸik deÄŸeri azaltmamÄ±z burada da ciddi fayda saÄŸladÄ± ancak halen sonuÃ§lara gÃ¶re yÃ¼ksek.\n",
    "\n",
    "SaÄŸ alt kutu (TP-TRUE POSÄ°TÄ°VE) BurasÄ± doÄŸru atÄ±ÅŸ yaptÄ±ÄŸÄ±mÄ±z yerler. MÃ¼ÅŸterinin aldÄ±ÄŸÄ± modelinde alacak dediÄŸi kÄ±sÄ±mdÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Bayesian Optimizasyonu ile Hiperparametre AyarÄ± \"\"\"\n",
    "\n",
    "import optuna #Â Bayesian optimizasyonu iÃ§in kullanÄ±lan popÃ¼ler kÃ¼tÃ¼phane\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Optuna'nÄ±n her denemede (trial) Ã§alÄ±ÅŸtÄ±racaÄŸÄ± fonksiyon\n",
    "    AmacÄ±: Rastgele parametreler seÃ§ip, modeli eÄŸitip, baÅŸarÄ± puanÄ±nÄ± dÃ¶ndÃ¼rmektir.\n",
    "\"\"\"\n",
    "def objective(trial):\n",
    "    \n",
    "    # 1-Denenecek Parametre UzayÄ± (Arama AlanÄ±)\n",
    "    params = {\n",
    "        # Temel parametreler bunlar fixtir deÄŸiÅŸmeyecekler\n",
    "        'objective': 'binary:logistic', # Ä°kili sÄ±nÄ±flandÄ±rma (0-1) yine\n",
    "        'tree_method': 'hist', # HÄ±zlandÄ±rma iÃ§in histogram tabanlÄ± yÃ¶ntem\n",
    "        'device': 'cuda',  # GPU kullanÄ±mÄ±\n",
    "        'eval_metric': 'logloss', # Hata Ã¶lÃ§Ã¼sÃ¼ (Log Loss) - DÃ¼ÅŸÃ¼rmeye Ã§alÄ±ÅŸacaÄŸÄ±z\n",
    "        \n",
    "        # Bu parametrelerde ise VerdiÄŸimiz aralÄ±klardan sayÄ±sal deÄŸerler seÃ§erek deniyecek\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1500), # AÄŸaÃ§ sayÄ±sÄ±\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1), # Ã–ÄŸrenme hÄ±zÄ±\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10), # AÄŸaÃ§ derinliÄŸi\n",
    "\n",
    "        # Regularization (DÃ¼zenleme) Parametreleri - en baÅŸta AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi engellemeye yardÄ±mcÄ± olur ve modelin genelleme yeteneÄŸini artÄ±rÄ±r\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0), # Her aÄŸaÃ§ta verinin % kaÃ§Ä±nÄ± kullansÄ±n?\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0), # Her aÄŸaÃ§ta Ã¶zelliklerin % kaÃ§Ä±nÄ± kullansÄ±n?\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5) # AÄŸacÄ±n bÃ¼yÃ¼mesini kontrol eden fren mekanizmasÄ±\n",
    "    }\n",
    "    \n",
    "    # 2-Modeli Kur (SeÃ§ilen parametrelerle)\n",
    "    model = xgb.XGBClassifier(**params, early_stopping_rounds=50) #Â seÃ§ilen parametreler ile model kuracak ve erken durdurma mekanizmasÄ± ekleyecek  \n",
    "    # (50 tur boyunca iyileÅŸme olmazsa dur demek)\n",
    "    \n",
    "    # 3-EÄŸitim\n",
    "    # Verbose=False yapÄ±yoruz ki ekranÄ± 20 kere eÄŸitim loglarÄ±yla doldurmasÄ±n. AÅŸaÄŸÄ±da kombinasyonu 20 yaptÄ±ÄŸÄ±mÄ±zdan.\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    # 4-Tahmin Yap (Validasyon Setinde)\n",
    "    # Burada parametreler kÄ±smÄ±nda verdiÄŸimiz Log Loss (Hata) deÄŸerini minimize etmeye Ã§alÄ±ÅŸacaÄŸÄ±z.\n",
    "    # Ã‡Ã¼nkÃ¼ Log Loss ne kadar dÃ¼ÅŸÃ¼kse, model o kadar \"kendinden emin\" demektir.\n",
    "    y_probs = model.predict_proba(X_val)[:, 1] # tine 1 sÄ±nÄ±fÄ±na ait \"alÄ±r\" olasÄ±lÄ±klarÄ±nÄ± alÄ±yoruz (0-1 arasÄ±nda deÄŸerler)\n",
    "    loss = log_loss(y_val, y_probs) #Â gerÃ§ek deÄŸerler ile tahmin edilen olasÄ±lÄ±klarÄ±n log loss deÄŸerini hesapla\n",
    "    #Â yani ceza deÄŸerleridir - Ã¶rneÄŸin kesin %99 alacak dedi ama almadÄ± Ã§ok ceza olur yani deÄŸer yÃ¼ksek, ama % 50 dedi ve almadÄ± daha az ceza olur yani deÄŸer dÃ¼ÅŸÃ¼k olur\n",
    "    \n",
    "    return loss\n",
    "\n",
    "print(\"Optuna ile en iyi parametreler aranÄ±yor\")\n",
    "\n",
    "# direction='minimize' -> Ã‡Ã¼nkÃ¼ Log Loss (Hata) deÄŸeri Ã¼zerinden gidiyoruz, bu yÃ¼zden minimize etmeye Ã§alÄ±ÅŸacaÄŸÄ±z.\n",
    "#Â eper yukarÄ±da loss deÄŸerleri yerine accuracy gibi bir baÅŸarÄ± metriÄŸi Ã¼zerinden gidiyor olsaydÄ±k direction='maximize' yapardÄ±k. yani doÄŸruluÄŸu yÃ¼kseltmeye uÄŸraÅŸsÄ±n diye\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20) # 20 farklÄ± kombinasyon dene\n",
    "# kombinasyon her deÄŸiÅŸtiÄŸinde objective fonksiyonu Ã§alÄ±ÅŸacak, yeni parametreler seÃ§ecek, modeli eÄŸitecek ve log loss deÄŸerini dÃ¶ndÃ¼recek duruma gÃ¶re deÄŸiÅŸimler yapÄ±p tekrar Ã§aÄŸÄ±rÄ±p Ã¶lÃ§ecek\n",
    "\n",
    "print(\"BULUNAN EN Ä°YÄ° PARAMETRELER:\")\n",
    "print(study.best_params)\n",
    "print(f\"En DÃ¼ÅŸÃ¼k Hata (LogLoss): {study.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BULUNAN EN Ä°YÄ° PARAMETRELER:\n",
    "{'n_estimators': 938, 'learning_rate': 0.03743533184090101, 'max_depth': 10, 'subsample': 0.6605204427574461, 'colsample_bytree': 0.7019846992999667, 'gamma': 1.54649974715052}\n",
    "En DÃ¼ÅŸÃ¼k Hata (LogLoss): 0.2632623644411835\n",
    "\n",
    "Bu sonuÃ§lar en iyi parametlerdir. Bunlar ve tekrar bu yeni model ile eÅŸik deÄŸeri ayarÄ± yapÄ±nca yeni modelimize kavuÅŸacaÄŸÄ±z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Yeni Parametrelerle Model EÄŸitimi \"\"\"\n",
    "\n",
    "# yukarda incelenmiÅŸ aynÄ± kodlar ile;\n",
    "# Optuna'dan gelen Kazanan Parametreler\n",
    "final_params = {\n",
    "    'n_estimators': 938,\n",
    "    'learning_rate': 0.03743533184090101,\n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.6605204427574461,\n",
    "    'colsample_bytree': 0.7019846992999667,\n",
    "    'gamma': 1.54649974715052,\n",
    "    \n",
    "    # Sabit Ayarlar\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda'\n",
    "}\n",
    "\n",
    "print(\"Model EÄŸitimi (Optimize Parametrelerle)\")\n",
    "final_model = xgb.XGBClassifier(**final_params, early_stopping_rounds=50)\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Yeni EÅŸik DeÄŸeri (Threshold) Bulma\n",
    "# Model deÄŸiÅŸtiÄŸi iÃ§in eski eÅŸik (0.20) artÄ±k geÃ§erli olmayabilir.\n",
    "print(\"\\nğŸ” Yeni model iÃ§in en iyi eÅŸik deÄŸeri aranÄ±yor...\")\n",
    "y_pred_probs = final_model.predict_proba(X_val)[:, 1]\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "for threshold in np.arange(0.1, 0.51, 0.01): # Daha hassas arama (0.01 adÄ±mlarla)\n",
    "    preds_custom = (y_pred_probs > threshold).astype(int)\n",
    "    f1 = f1_score(y_val, preds_custom)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"YENÄ° KAZANAN EÅÄ°K: {best_threshold:.2f}\")\n",
    "print(f\"YENÄ° F1 SKORU: {best_f1:.4f}\")\n",
    "\n",
    "final_preds = (y_pred_probs > best_threshold).astype(int)\n",
    "print(\"\\nOptimize EdilmiÅŸ Final Rapor:\")\n",
    "print(classification_report(y_val, final_preds))\n",
    "\n",
    "final_model.save_model(\"xgb_instacart_optimized_v2.json\")\n",
    "print(\"\\nModel kaydedildi: xgb_instacart_optimized_v2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã‡Ä±kan sonuÃ§lara gÃ¶re yine aynÄ± eÅŸik deÄŸer 0.20 ve f1 skoruda 0.3932 yani ayar yapÄ±lmamÄ±ÅŸ modelden binde 2 daha dÃ¼ÅŸÃ¼k yani aynÄ±. DiÄŸer deÄŸerlerde birebir aynÄ± buradan Ã§Ä±karacaÄŸÄ±mÄ±z ÅŸey EDA kÄ±smÄ±ndan alabileceÄŸimiz her ÅŸeyi almÄ±ÅŸÄ±z model saten tÃ¼m veridÄŸimiz Ã¶zellikleri yutmuÅŸ daha fazla birÅŸey Ã§Ä±karamam diyor bundan dolayÄ± future kÄ±smÄ±na dÃ¶nÃ¼p orada geliÅŸtirme yapacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Yeni Ã–zelliklerle (v2) Model EÄŸitimi \"\"\"\n",
    "\n",
    "#Â yeni v2 model Ã¶zellikleri eklediÄŸimden eÄŸitim iÃ§in gÃ¶nderdiÄŸimiz veri setini de deÄŸiÅŸtirmemiz gerekiyor. \n",
    "# O yÃ¼zden tekrar veri yÃ¼kleme kÄ±smÄ±na yenisini gÃ¶nderiyoruz - totalde 8.5M satÄ±r\n",
    "DATA_PATH = \"/kaggle/input/train-v2/train_data.csv\"\n",
    "print(\"Veri yÃ¼kleniyor\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Eksik veri kontrolÃ¼ (Yok hallettikde garanti olsun null olmasÄ±n eksik varsa doldurma)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Ã–zellikleri ve Hedefi AyÄ±r\n",
    "# ArtÄ±k X'in iÃ§inde yeni eklediÄŸimiz 'orders_since_last_bought' vb. hepsi var.\n",
    "# bu Ã¼Ã§Ã¼nÃ¼ Ã§Ä±karmamÄ±z yetiyor kalan hepsini x olarak alacak\n",
    "X = df.drop(['user_id', 'product_id', 'reordered'], axis=1)\n",
    "y = df['reordered']\n",
    "\n",
    "print(f\"Veri HazÄ±r, Ã–zellik SayÄ±sÄ±: {X.shape[1]}\")\n",
    "print(\"Ã–zellik Listesi:\", list(X.columns)) #Â kaÃ§Ä±rdÄ±ÄŸÄ±mÄ±z olmasÄ±n gÃ¶zden geÃ§irelim diye Ã¶zelliklerin listesini de basÄ±yoruz\n",
    "\n",
    "# EÄŸitim ve Test Setine BÃ¶l (%80 - %20)\n",
    "print(\"\\n Veri bÃ¶lÃ¼nÃ¼yor\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optuna Ä°le BulduÄŸumuz en iyi Parametreler\n",
    "params = {\n",
    "    'n_estimators': 938,\n",
    "    'learning_rate': 0.03743533184090101,\n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.6605204427574461,\n",
    "    'colsample_bytree': 0.7019846992999667,\n",
    "    'gamma': 1.54649974715052,\n",
    "    \n",
    "    # Sabitler\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' # GPU yoksa 'cpu' yap yoksa hÄ±zlanmaz\n",
    "}\n",
    "\n",
    "# Modeli EÄŸit\n",
    "print(\"\\n Final Model EÄŸitimi BaÅŸlÄ±yor\")\n",
    "model = xgb.XGBClassifier(**params, early_stopping_rounds=50)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=100 # Her 100 aÄŸaÃ§ta bir rapor verecek loss deÄŸerini filan arada gÃ¶rmemiz nasÄ±l gittiÄŸini anlamamÄ±zÄ± saÄŸlar\n",
    ")\n",
    "\n",
    "# Yine garanti olsun bu setinde En Ä°yi EÅŸik DeÄŸerini (Threshold) BulalÄ±m\n",
    "print(\"\\n En iyi eÅŸik deÄŸeri aranÄ±yor\")\n",
    "y_pred_probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "best_threshold = 0.20 # BaÅŸlangÄ±Ã§ (Ã¶nceki en iyiydi)\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in np.arange(0.15, 0.45, 0.01):\n",
    "    preds = (y_pred_probs > threshold).astype(int)\n",
    "    score = f1_score(y_val, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"KAZANAN EÅÄ°K: {best_threshold:.2f}\")\n",
    "print(f\"YENÄ° F1 SKORU: {best_f1:.4f}\")\n",
    "\n",
    "# DetaylÄ± Rapor\n",
    "final_preds = (y_pred_probs > best_threshold).astype(int)\n",
    "print(\"\\n Final Karne:\")\n",
    "print(classification_report(y_val, final_preds))\n",
    "\n",
    "# Hangi Ã–zellik Ä°ÅŸe YaradÄ± (Feature Importance) diÄŸerlerine gÃ¶re gÃ¶receli olarak hangi Ã¶zellikler daha etkili olmuÅŸ karar verirken\n",
    "plt.figure(figsize=(10, 6))\n",
    "xgb.plot_importance(model, max_num_features=15, importance_type='weight', title='Hangi Ã–zellik En Ã‡ok Ä°ÅŸe YaradÄ±')\n",
    "plt.show()\n",
    "\n",
    "# Modeli Kaydet\n",
    "model.save_model(\"xgb_final_v3.json\")\n",
    "print(\"\\n Model Kaydedildi: xgb_final_v3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã¶ncelikle yeni eÅŸik deÄŸeri 0.22 oldu. f1 skoru 0.43 hatasÄ±da 0.24 geldi. bu oranlar Ã¶nceki modele gÃ¶re Ã§ok ciddi daha iyi. Ã¼stelik recall (yani balÄ±ÄŸÄ± tutma diyim) deÄŸeri %49 a ulaÅŸtÄ± yani her iki Ã¶nermemizden birinde mÃ¼ÅŸteriyi yakalÄ±yoruz. SÃ¼priz ise en Ã§ok kullandÄ±ÄŸÄ± Ã¶zelliklerde oldu. user_avg_basket_size Ã¶zelliÄŸini en Ã§ok kullanmÄ±ÅŸ yani artÄ±k diÄŸer model gibi en popÃ¼ler hangisi ise reorder_Ratio deÄŸerine (ÅŸimdiki modelde bu deÄŸer en altta) gÃ¶re deÄŸilde gerÃ§ekten mÃ¼ÅŸteriyi analiz ederek kararlar veriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" KarÄ±ÅŸÄ±klÄ±k Matrisi \"\"\"\n",
    "# Tahminleri EÅŸik DeÄŸerine GÃ¶re Yap (0.22 bulmuÅŸtuk)\n",
    "# matris iÃ§in alÄ±r-almaz tahminlerini yapalÄ±m. \n",
    "# Ã§Ã¼nkÃ¼ matris probs dan Ã§Ä±kan sayÄ±sal deÄŸerli Ã¶rneÄŸin 0.88 alÄ±r gibi ifadelerden anlamaz onun yerine 0-1 alÄ±r-almaz kesin kodlarla yaparÄ±z\n",
    "threshold = best_threshold \n",
    "preds = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "# Matrisi Hesapla\n",
    "cm = confusion_matrix(y_val, preds)\n",
    "\n",
    "# GÃ¶rselleÅŸtir (Heatmap)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Tahmin: Almaz (0)', 'Tahmin: AlÄ±r (1)'],\n",
    "            yticklabels=['GerÃ§ek: AlmadÄ± (0)', 'GerÃ§ek: AldÄ± (1)'])\n",
    "plt.ylabel('GerÃ§ek Durum')\n",
    "plt.xlabel('Modelin Tahmini')\n",
    "plt.title(f'Final Model KarÄ±ÅŸÄ±klÄ±k Matrisi (EÅŸik: {threshold:.2f})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TN - Saten Ã§oÄŸu belli olan durumlar. Ã¶nemsizdir. mÃ¼ÅŸterinin almadÄ±ÄŸÄ± modelinde almayacak dediÄŸi\n",
    "\n",
    "FP - Model Alacak dedi ama mÃ¼ÅŸteri almadÄ±. Bu kÃ¶tÃ¼ bir ÅŸey deÄŸil aslÄ±nda. E-ticaret sitelerinde BunlarÄ± da sevebilirsiniz kÄ±smÄ±nda Ã§Ä±kan ama tÄ±klamadÄ±ÄŸÄ±n Ã¼rÃ¼nlerdir. MÃ¼ÅŸteriyi Ã§ok rahatsÄ±z etmez, sadece bir Ã¶neridir.\n",
    "\n",
    "FN - MÃ¼ÅŸteri Ã¼rÃ¼nÃ¼ aldÄ± ama model Almaz sanÄ±yordu burasÄ± kaÃ§an fÄ±rsattÄ±r. Ã¶nceki modelden yaklaÅŸÄ±k %5 daha iyi durumda. Bu sektÃ¶r iÃ§in bu deÄŸer gayet iyiymiÅŸ. asÄ±l odaklanmamÄ±z gereken kÄ±sÄ±mdÄ±r.\n",
    "\n",
    "TP - BurasÄ± doÄŸru bildiÄŸimiz mÃ¼ÅŸterinin aldÄ±ÄŸÄ±, modelinde alacak dediÄŸi yerdir. yani direkt kasaya giren paradÄ±r."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
