{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAGGLE ile hibrit model ÅŸeklinde gidilmektedir. Veri iÅŸlemesi lokalde yapÄ±lÄ±rken, Model eÄŸitimi kaggle Ã¼zerinden yapÄ±lmaktadÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu dosya kaggle da eÄŸitilen modelin kodlarÄ±nÄ± ve geliÅŸimini arÅŸivlemek aÃ§Ä±sÄ±ndan birebir kod ve aÃ§Ä±klamalarÄ±dÄ±r. (Ã‡Ä±ktÄ±larÄ± Kendiniz Ã‡alÄ±ÅŸtÄ±rabilirsiniz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" VERÄ° YÃœKLEME \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model iÃ§in hazÄ±rladÄ±ÄŸÄ±mÄ±z train.data verisi seti\n",
    "df = pd.read_csv(\"/kaggle/input/instacart-features-local/train_data.csv\")\n",
    "\n",
    "print(f\"âœ… Veri yÃ¼klendi! Boyut: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create_Dataset dosyasÄ± ile son hale getirdiÄŸimiz eÄŸitim iÃ§in veri setini sisteme yÃ¼kledik ve burada Ã§ekiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEÄÄ°ÅKENLERÄ°N HAZIRLANMASI \"\"\"\n",
    "\n",
    "X = df.drop(['user_id', 'product_id', 'reordered'], axis=1) # deÄŸiÅŸkenler\n",
    "y = df['reordered'] # hedef\n",
    "\n",
    "# %80 EÄŸitim, %20 test\n",
    "print(\"ğŸ”ª Veri setleri ayrÄ±lÄ±yor...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"EÄŸitim Seti: {X_train.shape}\")\n",
    "print(f\"Test Seti:   {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin kullanÄ±cÄ±, Ã¼rÃ¼n ve tahmin etmesi gereken (hedef deÄŸiÅŸken) sÃ¼tunlarÄ±nÄ± gÃ¶rmemesi iÃ§in kaldÄ±rÄ±yoruz diÄŸerlerini alacak. eÄŸer kaldÄ±rmaz isek model bunlarÄ± baz alarak Ã¶ÄŸrenmek yerine ezber yapar. Yani ahmet ÅŸunu almÄ±ÅŸ, muz bu kadar alÄ±nÄ±yor gibi ezberden kaÃ§Ä±nsÄ±n. EÄŸer Ã¼rÃ¼n popÃ¼lerse ve kullanÄ±cÄ± daha Ã¶nce Ã§ok aldÄ±ysa cevap Evet' yani tekrar alÄ±r demesi lazÄ±m bu mantÄ±kla yaklaÅŸmalÄ±.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" XGBOOST MODELÄ°NÄ°N AYARLARI \"\"\"\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', #Â Ä°kili sÄ±nÄ±flandÄ±rmadÄ±r. (binary ikili durumu ifade eder evet-hayÄ±r,alacak-almÄ±ycak gibi, logistic ise sÄ±nÄ±flandÄ±rma iÃ§in kullanÄ±rÄ±z direkt 0,1 vermesin kÃ¼sÃ¼ratlÄ±da versin)\n",
    "    eval_metric='logloss', # puan sistemi (Ã‡ok eminse ve yanlÄ±ÅŸ Ã§Ä±karsa bÃ¼yÃ¼k ceza gibi tahminle orantÄ±lÄ± ceza)\n",
    "    n_estimators=1000,      # AÄŸaÃ§ sayÄ±sÄ±\n",
    "    learning_rate=0.05,     # Ã–ÄŸrenme hÄ±zÄ±\n",
    "    max_depth=6,            # AÄŸaÃ§ derinliÄŸi\n",
    "    tree_method='hist',     # HÄ±zlandÄ±rma iÃ§in (histogram ile veriyi gruplayarak iÅŸlem yapsÄ±n. hÄ±z katar.)\n",
    "    device='cuda',          # GPU kullanÄ±mÄ± (EÄŸer GPU aÃ§tÄ±ysan 'cuda', aÃ§madÄ±ysan 'cpu' yap)\n",
    "    early_stopping_rounds=50 # EÄŸer 50 tur boyunca iyileÅŸme olmazsa dur\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)], # her aÄŸaÃ§tan sonra gÃ¶rmediÄŸi verilerle test yapra\n",
    "    verbose=100  # Her 100 adÄ±mda(aÄŸaÃ§ta) bir durum raporu ver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TAHMÄ°N \"\"\"\n",
    "\n",
    "# Tahmin yap\n",
    "y_pred = model.predict(X_val) #Â x_val verileri ile tahmin ettirme\n",
    "# 0 ve 1 leden oluÅŸan tahmin sonuÃ§larÄ± y_pred de\n",
    "\n",
    "# Raporla\n",
    "print(\"ğŸ“Š Model PerformansÄ±:\")\n",
    "print(classification_report(y_val, y_pred)) # y_val gerÃ§ek cevaplar ile y_pred tahminlerin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±\n",
    "\n",
    "# Hangi Ã¶zellik en Ã¶nemlisi (Interpretabilitiy)\n",
    "xgb.plot_importance(model, max_num_features=10)  # karar verirken en Ã§ok kullandÄ±ÄŸÄ± Ã¶zellikleri sÄ±ralar\n",
    "plt.title(\"Hangi Ã–zellik Daha Ã–nemli?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() metodunda varsayÄ±lan olarak eÅŸik deÄŸer %50 dir. Yani 1 (alÄ±r) sonucunu vermesi iÃ§in %50.01 ikna olmasÄ± yeterlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_report() metodu ceaplarÄ±n kontrolÃ¼nÃ¼ yapar. Direkt ÅŸu kadar bildi (accuracy) Ã¶lÃ§mez genel bir test yapar. \n",
    "\n",
    "Testte Precision (Kesinlik): \"Alacak\" dediklerinin yÃ¼zde kaÃ§Ä± gerÃ§ekten aldÄ±\n",
    "\n",
    "Recall (DuyarlÄ±lÄ±k - En Ã–nemlisi): GerÃ§ekten alanlarÄ±n yÃ¼zde kaÃ§Ä±nÄ± yakalayabildi\n",
    "\n",
    "F1-Score: Precision ve Recall'un ortalamasÄ±. Modelin genel dengesi. (direkt bu metrik Ã§ok ÅŸey ifade eder)\n",
    "\n",
    "Support: o sÄ±nÄ±ftan (0 veya 1) test setinde kaÃ§ tane Ã¶rnek olduÄŸu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretability kÄ±smÄ± analiz iÃ§in Ã§ok Ã¶nemlidir. Ä°lk sonuÃ§lar genelde hiÃ§ iÃ§ aÃ§Ä±cÄ± olmayakcaktÄ±r. Bunun tedavisinide en kÄ±sa ve kesin yoldan bu adÄ±m ile saptayabilir. Modele bu kararlarÄ± verirken hangi Ã¶zellikleri kullandÄ±n diye sorar. Bu da model gerÃ§ekten bizim istediÄŸimiz mantÄ±k da dÃ¼ÅŸÃ¼nÃ¼p dÃ¼ÅŸÃ¼nmediÄŸini gÃ¶sterir ve nokta atÄ±ÅŸÄ± tedavi yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1-Tahminlerin ihtimal oranlarÄ± (yani karar verirken ne kadar oranlar ile verdin)\n",
    "print(\"OlasÄ±lÄ±klar hesaplanÄ±yor\")\n",
    "y_pred_probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "\n",
    "# 2-En iyi eÅŸik deÄŸerini (Threshold) bulma dÃ¶ngÃ¼sÃ¼\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "results = []\n",
    "\n",
    "print(\"En iyi eÅŸik deÄŸeri aranÄ±yor\")\n",
    "\n",
    "# 0.10'dan 0.50'ye kadar 0.02 adÄ±m adÄ±m dene\n",
    "for threshold in np.arange(0.1, 0.51, 0.02):\n",
    "    # OlasÄ±lÄ±k > threshold ise 1 yap, deÄŸilse 0\n",
    "    preds_custom = (y_pred_probs > threshold).astype(int) # karÅŸÄ±laÅŸtÄ±rma\n",
    "    \n",
    "    # F1 Skorunu hesapla (Class 1 iÃ§in)\n",
    "    f1 = f1_score(y_val, preds_custom) # her eÅŸiÄŸe gÃ¶re hesaplamadÄ±ÄŸÄ±mÄ±z sÄ±nÄ±f ile gerÃ§ek deÄŸerler f1 skorunu hesapla\n",
    "    results.append((threshold, f1)) #Â bu Ã¶lÃ§Ã¼mleri karÅŸÄ±laÅŸtÄ±rmak Ã¼zere listeye atÄ±yoruz\n",
    "    \n",
    "    print(f\"   EÅŸik: {threshold:.2f} -> F1 Score: {f1:.4f}\") #Â her dÃ¶ngÃ¼ sonucu\n",
    "    \n",
    "    # en iyi f1 skoru seÃ§imi\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"EN Ä°YÄ° EÅÄ°K DEÄERÄ°: {best_threshold:.2f}\")\n",
    "print(f\"Yeni F1 Skoru: {best_f1:.4f}\")\n",
    "\n",
    "\n",
    "# 3-En iyi eÅŸik ile DETAYLI raporu bas\n",
    "final_preds = (y_pred_probs > best_threshold).astype(int) #Â en iyi eÅŸik deÄŸeri al\n",
    "\n",
    "print(\"\\nOptimize EdilmiÅŸ Rapor:\")\n",
    "print(classification_report(y_val, final_preds)) #Â alÄ±nan deÄŸerler tekrardan report metodu ile raporla\n",
    "\n",
    "\n",
    "# 4-KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix) - Neyi ne kadar doÄŸru bildik gÃ¶rmek iÃ§in\n",
    "cm = confusion_matrix(y_val, final_preds) #Â cevaplar ile bizim en iyi f1 li tahmnilerimiz\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix (Threshold: {best_threshold:.2f})')\n",
    "plt.ylabel('GerÃ§ek DeÄŸer')\n",
    "plt.xlabel('Tahmin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba() ile bu sefer ihtimalleri alÄ±yoruz. yani sen sÄ±nÄ±flandÄ±rma (0 alma, 1 al) yaparken %50 Ã¼stÃ¼ olunca 1 diyosun ama  ne kadar oran verdin her veri iÃ§in diye soruyoruz. geriye her tahmini iÃ§in [[0.3, 0.7], [0.8, 0.2], ...] gibi bir Ã§Ä±ktÄ± dÃ¶ner biz de sadece saÄŸdaki yani 1.indeksteki 1(alÄ±r) iÃ§in olan oranlarÄ± alÄ±yoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred default olarak threshold deÄŸerini %50 alÄ±r yani 50.1 olduÄŸu an 1 verir. Burada Ã§ok korkak davrandÄ±ÄŸÄ± tespit ettik Ã§Ä±kan sonuÃ§larda. Bu deÄŸerin en optimum sonuÃ§larÄ± ne kadarken verdiÄŸini gÃ¶rmek iÃ§in tÃ¼m deÄŸeleri ufak adÄ±mlarla deÄŸiÅŸtire deÄŸiÅŸtire deniyoruz. ihtimalleri aldÄ±ÄŸÄ±mÄ±z kÄ±sÄ±m ile sÃ¼rekli denediÄŸimiz eÅŸik deÄŸeri karÅŸÄ±laÅŸtÄ±rÄ±p deniyoruz. En iyi sonucu veren f1 skorlu deÄŸerli report fonkisyonu ile detaylÄ± raporluyoruz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son olarak karÄ±ÅŸÄ±klÄ±k matrisi ile rÃ¶ntgen Ã§ekiyoruz. Bu matriste satÄ±rlar GerÃ§ek Durumu, sÃ¼tunlar ise Modelin Tahminini gÃ¶sterir. Her kutunun ise ayrÄ± bir anlamÄ± vardÄ±r. \n",
    "\n",
    "Sol Ã¼st kutu (TN-TRUE NEGATÄ°VE) Buraya sessiz doÄŸru deneriz. burada mÃ¼ÅŸterinin almayacaÄŸÄ± Ã¼rÃ¼ne modelinde almayacak demesidir. saten bu durum her problemde genelde doÄŸrudur. Ã‡Ã¼nkÃ¼ bu durumda bulunan bi ton veri saten hep vardÄ±r.\n",
    "\n",
    "SaÄŸ Ã¼st kutu (FP-FALSE POSITIVE) YanlÄ±ÅŸ alarm verdiÄŸimiz durumlar. MÃ¼ÅŸterinin almayacaÄŸÄ± Ã¼rÃ¼ne modelin alacak demesidir. Bu oran son yaptÄ±ÄŸÄ±mÄ±z eÅŸik deÄŸeri 50 den 20 ye dÃ¼ÅŸÃ¼rme iÅŸlemimizden sonra ciddi arttÄ±. Ã‡Ã¼nkÃ¼ model Ã§ok daha sÄ±k alacak dediÄŸi iÃ§in hata oranÄ±da arttÄ±. Bu sorun bu problem iÃ§in gÃ¶z ardÄ± edilebilir Ã§Ã¼nkÃ¼ mÃ¼ÅŸteriye Ã¼rÃ¼n Ã¶nerme maliyeti dÃ¼ÅŸÃ¼ktÃ¼r ama bu Ã¶nermeye karÅŸÄ±lÄ±k vermesi Ã¶nemli olduÄŸundan maliyet-kazanÃ§ oranÄ±mÄ±z yÃ¼ksektir bundan dolayÄ± burada ki hata payÄ± gÃ¶z ardÄ± edilebilir. (biz az ihtimalde olsa Ã¶nerelim maliyeti yok ya alÄ±rsa gibi)\n",
    "\n",
    "Sol alt kutu (FN-FALSE NEGATIVE) Bu kÄ±sÄ±m farkÄ± yaratacaÄŸÄ±mÄ±z, problemin ana amaÃ§ kÄ±smÄ±dÄ±r. MÃ¼ÅŸterinin aldÄ±ÄŸÄ± ancak biz almayacak diyip de Ã¶nermede bulunmadÄ±ÄŸÄ±mÄ±z kÄ±sÄ±mdÄ±r. EÅŸik deÄŸeri azaltmamÄ±z burada da ciddi fayda saÄŸladÄ± ancak halen sonuÃ§lara gÃ¶re yÃ¼ksek.\n",
    "\n",
    "SaÄŸ alt kutu (TP-TRUE POSÄ°TÄ°VE) BurasÄ± doÄŸru atÄ±ÅŸ yaptÄ±ÄŸÄ±mÄ±z yerler. MÃ¼ÅŸterinin aldÄ±ÄŸÄ± modelinde alacak dediÄŸi kÄ±sÄ±mdÄ±r."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
