import pandas as pd
import sqlite3
import time
from pathlib import Path

"""
Bu dosya; veritabanÄ±ndaki daÄŸÄ±nÄ±k istatistikleri alÄ±r, geÃ§miÅŸ alÄ±ÅŸveriÅŸlere bakarak bir "Aday Listesi" Ã§Ä±karÄ±r, 
sonra da "Son sipariÅŸte bunlarÄ± aldÄ± mÄ±?" diye kontrol ederek (ayÄ±rdÄ±ÄŸÄ±mÄ±z test verilerinden kontrolÃ¼ yapar) yanÄ±na 1 veya 0 yazar. Bu Ã¼rÃ¼nler Ã¼zerinden kiÅŸiye Ã¶zel Ã§Ä±karÄ±m yapar tÃ¼m Ã¼rÃ¼nler ile iliÅŸkilendirmez.
Ã‡Ä±kan sonuÃ§, modelin ders Ã§alÄ±ÅŸacaÄŸÄ± kitaptÄ±r. yani gÃ¶zetimli Ã¶ÄŸrenme yapÄ±yoruz veriyi ver tahmin etsin sonra kontrol et yanlÄ±ÅŸlarÄ±nÄ±n Ã¼zerinden geÃ§sin
"""

# --- AYARLAR ---
BASE_DIR = Path(__file__).resolve().parent.parent # Proje kÃ¶k dizini
DB_PATH = BASE_DIR / "data" / "processed" / "instacart.db" # veritabanÄ± yolu
OUTPUT_DIR = BASE_DIR / "data" / "processed" # modele verilecek veri dosyasÄ±nÄ±n Ã§Ä±ktÄ± dizini


"""
VeritabanÄ±na baÄŸlanÄ±r
"""
def get_db_connection():
    return sqlite3.connect(DB_PATH)


"""
    Model eÄŸitimi iÃ§in gerekli olan 'Master Table'Ä± oluÅŸturur ve CSV olarak kaydeder.
    Bu tablo ÅŸunlarÄ± iÃ§erir:
    - user_id, product_id
    - TÃ¼m featurelar (user, product, uxp)
    - TARGET (reordered): 1 (aldÄ±) veya 0 (almadÄ±) -> tahmine gÃ¶re 1 veya 0 yazar
"""
def create_train_dataset():

    print("ðŸš‚ EÄŸitim Verisi (Train Dataset) hazÄ±rlanÄ±yor...")
    start_time = time.time() # Zaman Ã¶lÃ§Ã¼mÃ¼ iÃ§in
    conn = get_db_connection() # VeritabanÄ±na baÄŸlan
    
    # --- MODELE VERÄ°LECEK VERÄ°NÄ°N MANTIÄžI -> ADAY BELÄ°RLEME (CANDIDATE GENERATION) ---
    # Her kullanÄ±cÄ± iÃ§in tÃ¼m marketteki 50.000 Ã¼rÃ¼nÃ¼ tahmin etmeye Ã§alÄ±ÅŸamayÄ±z.
    # Sadece kullanÄ±cÄ±nÄ±n "daha Ã¶nce en az bir kez aldÄ±ÄŸÄ±" Ã¼rÃ¼nleri (uxp_features tablosundakileri)
    # aday olarak seÃ§iyoruz. Buna "Candidate Generation" denir.
    
    query = """
    SELECT 
        -- Kimlikler
        o.user_id, -- KullanÄ±cÄ± ID
        uxp.product_id, -- ÃœrÃ¼n ID
        
        -- Featurelar (Ã–zellikler - Daha Ã¶nce hesaplayÄ±p tablolara attÄ±ÄŸÄ±mÄ±z istatistikler)
        uxp.uxp_total_bought, -- KullanÄ±cÄ±nÄ±n bu Ã¼rÃ¼nÃ¼ kaÃ§ kere aldÄ±ÄŸÄ±
        uxp.uxp_reorder_ratio, -- KullanÄ±cÄ±nÄ±n bu Ã¼rÃ¼nÃ¼ tekrar alma oranÄ±
        uf.user_total_orders, -- KullanÄ±cÄ±nÄ±n toplam sipariÅŸ sayÄ±sÄ±
        uf.user_avg_days_between, -- KullanÄ±cÄ±nÄ±n ortalama sipariÅŸler arasÄ± gÃ¼n sayÄ±sÄ±
        pf.prod_total_orders, -- ÃœrÃ¼nÃ¼n toplam sipariÅŸ sayÄ±sÄ±
        pf.prod_reorder_rate, -- ÃœrÃ¼nÃ¼n tekrar sipariÅŸ edilme oranÄ±
        
        -- Hedef DeÄŸiÅŸken - Cevap anahtarÄ± (Target Finding -> Bu Ã¼rÃ¼n son sipariÅŸte gerÃ§ekten alÄ±ndÄ± mÄ±)
        -- EÄŸer train setindeki sipariÅŸte bu Ã¼rÃ¼n varsa 1, yoksa 0.
        CASE 
            WHEN op_train.reordered = 1 THEN 1  -- EÄŸer Ã¼rÃ¼n son sepette varsa 1
            ELSE 0  -- Yoksa 0
        END as reordered -- Hedef deÄŸiÅŸken (SipariÅŸ edildi mi 0(null) yada 1 olarak kaydedecek)
        

    FROM orders o -- TÃ¼m sipariÅŸler tablosundan baÅŸla
    
    -- 1- Sadece 'train' setindeki kullanÄ±cÄ±larÄ± al (CevabÄ±nÄ± bildiklerimiz)
    JOIN uxp_features uxp ON o.user_id = uxp.user_id -- KullanÄ±cÄ±-ÃœrÃ¼n Ã¶zellik tablosu ile eÅŸleÅŸtir 
    -- (kim geÃ§miÅŸte neyi almÄ±ÅŸ bÃ¶ylece 50bin Ã¼rÃ¼nden 50-100 Ã¼rÃ¼ne dÃ¼ÅŸtÃ¼ kullanÄ±cÄ± baÅŸÄ± araÅŸtÄ±rÄ±lmasÄ± gereken Ã¼rÃ¼n)
    
    -- 2- Ã–zellik TablolarÄ±nÄ± BaÄŸla (aslÄ±nda burada veri kaybÄ±nÄ± Ã¶nlemek iÃ§in LEFT JOIN kullanÄ±yoruz, inner kullansak bazen hesaplanamayan kullanÄ±cÄ±lar olduÄŸundan onlarÄ± yok sayacak)
    LEFT JOIN user_features uf ON o.user_id = uf.user_id
    LEFT JOIN product_features pf ON uxp.product_id = pf.product_id
    
    -- 3- Hedefi Bul (Bu Ã¼rÃ¼n son sipariÅŸte var mÄ±?), order_products__train tablosuna bakÄ±yoruz.
    LEFT JOIN order_products__train op_train  -- SipariÅŸ-ÃœrÃ¼n tablosu ile eÅŸleÅŸtir
        ON o.order_id = op_train.order_id  -- SipariÅŸ ID'leri eÅŸleÅŸmeli
        AND uxp.product_id = op_train.product_id -- ÃœrÃ¼n ID'leri eÅŸleÅŸmeli
        
    WHERE o.eval_set = 'train' -- Sadece 'train' setindeki sipariÅŸleri al teste dokunma
    """
    
    # Veriyi Ã§ek (Chunking kullanmÄ±yoruz, yaklaÅŸÄ±k 8-10 milyon satÄ±r olabilir
    print("   --> SQL Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor (Bu iÅŸlem biraz RAM tÃ¼ketebilir)...")
    df = pd.read_sql(query, conn)
    
    # Eksik verileri (NaN) doldurma. yukarÄ±da inner yerine Left joinlerden dolayÄ± bazÄ± Ã¶zellikler boÅŸ gelebilir, onlarÄ± 0 yapÄ±yoruz. null olmasÄ±n makine sevmez
    df = df.fillna(0)
    
    print(f"   --> {len(df):,} satÄ±rlÄ±k veri seti oluÅŸturuldu.")
    
    # CSV'ye kaydet, kaggleda Ã§alÄ±ÅŸtÄ±rÄ±caz
    output_path = OUTPUT_DIR / "train_data.csv"
    print(f"   --> CSV kaydediliyor: {output_path}")
    df.to_csv(output_path, index=False)
    
    conn.close()
    print(f"âœ… TamamlandÄ±! SÃ¼re: {time.time() - start_time:.2f} sn")

if __name__ == "__main__":
    create_train_dataset()