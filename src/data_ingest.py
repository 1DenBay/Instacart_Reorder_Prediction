import pandas as pd
import sqlite3
import os
from pathlib import Path
import time

# --- AYARLAR ---
# Projenin ana dizinini bulur
BASE_DIR = Path(__file__).resolve().parent.parent #bilgisayarda dosya yolu
DATA_RAW = BASE_DIR / "data" / "raw" # ham verilerin bulunduÄŸu klasÃ¶r
DB_PATH = BASE_DIR / "data" / "processed" / "instacart.db" # SQLite veritabanÄ± dosyasÄ±, final yeri

def ingest_data():
    """
    CSV dosyalarÄ±nÄ± okur ve SQLite veritabanÄ±na kaydeder.
    """
    print(f"ğŸš€ Veri aktarÄ±mÄ± baÅŸlÄ±yor...")
    print(f"ğŸ“‚ Kaynak: {DATA_RAW}")
    print(f"ğŸ’¾ Hedef: {DB_PATH}")
    
    # VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± aÃ§ (yoksa oluÅŸturur)
    conn = sqlite3.connect(DB_PATH) # db nin bulunduÄŸu yer
    
    # Ä°ÅŸlenecek dosyalar listesi
    files = [
        'aisles.csv',
        'departments.csv',
        'products.csv',
        'orders.csv',
        'order_products__train.csv',
        'order_products__prior.csv' # En bÃ¼yÃ¼k dosya sona saklandÄ±
    ]

    start_total = time.time() #Â Toplam sÃ¼re Ã¶lÃ§Ã¼mÃ¼ iÃ§in baÅŸlangÄ±Ã§ zamanÄ±

    for file_name in files: # tablo adÄ± iÃ§in dosyalarÄ±n uzantÄ±larÄ± kaldÄ±rÄ±r ve aynÄ± isimle tablosunu oluÅŸturur
        file_path = DATA_RAW / file_name
        table_name = file_name.replace('.csv', '') # Ã¶rn: aisles 
        
        if not file_path.exists():
            print(f"âš ï¸ UYARI: {file_name} bulunamadÄ±, atlanÄ±yor.")
            continue

        print(f"\n--> â³ {file_name} okunuyor ve '{table_name}' tablosuna yazÄ±lÄ±yor...")
        
        #Â ETL -> LOAD kÄ±smÄ± , CSV okuma
        # Not: GerÃ§ek hayatta TB'lÄ±k verilerde yada RAM in kaldÄ±rmayacaÄŸÄ± bÃ¼yÃ¼klÃ¼ktekilerde 'chunksize' parametresini kullanÄ±rÄ±z. Bu sayede bÃ¼yÃ¼k veriyi parÃ§alar halinde okur ve yazarÄ±z.
        # Ã–rnek: pd.read_csv(file_path, chunksize=100000) -> 100.000 satÄ±rlÄ±k parÃ§alar halinde okur ve iÅŸler.
        # veri seti = 550MB ram kaldÄ±rdÄ±ÄŸÄ±ndan bÃ¶yle bir iÅŸleme gerek yok
        start = time.time()
        df = pd.read_csv(file_path)
        
        # SQL'e yazma
        # if_exists='replace': Tablo varsa siler yeniden oluÅŸturur (geliÅŸtirme aÅŸamasÄ±nda pratik)
        # index=False: Pandas indexini veritabanÄ±na yazmasÄ±n Ã§Ã¼nkÃ¼ gereksiz yer kaplÄ±yor
        df.to_sql(table_name, conn, if_exists='replace', index=False)
        
        # start time baÅŸlangÄ±Ã§tÄ± bu da bitiÅŸ noktasÄ± performans Ã¶lÃ§Ã¼mÃ¼ iÃ§in
        end = time.time()
        print(f"    âœ… TamamlandÄ±! {len(df):,} satÄ±r eklendi. (SÃ¼re: {end-start:.2f} sn)")

    conn.close()
    print(f"\nğŸ‰ TÃœM Ä°ÅLEMLER BÄ°TTÄ°! Toplam SÃ¼re: {time.time() - start_total:.2f} sn")

 #Â klasik Python main guard. terminalden direkt bu dosyayÄ± Ã§alÄ±ÅŸtÄ±rÄ±rsak direkt Ã§alÄ±ÅŸsÄ±n
 # ama baÅŸka dosyaya import ederek Ã§aÄŸÄ±rÄ±p Ã§alÄ±ÅŸtÄ±rÄ±yorsak beklesin hemen Ã§alÄ±ÅŸmasÄ±n
if __name__ == "__main__":
    ingest_data()